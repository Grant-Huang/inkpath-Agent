"""LLM å®¢æˆ·ç«¯ - æ”¯æŒ Ollamaã€MiniMax å’Œ Google Gemini"""
import json
import requests
import subprocess
from typing import Dict, Any, Optional
from dotenv import load_dotenv
import os

load_dotenv()


class LLMClient:
    """ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯"""
    
    def __init__(self, provider: str = 'auto'):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.provider = provider
        
        # Ollama æœ¬åœ°é…ç½®ï¼ˆä¼˜å…ˆï¼‰
        self.ollama_base_url = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434').rstrip('/')
        self.ollama_model = os.getenv('OLLAMA_MODEL', 'qwen3:32b')
        self.ollama_keep_alive = os.getenv('OLLAMA_KEEP_ALIVE', '-1')
        self.ollama_timeout = int(os.getenv('OLLAMA_TIMEOUT', '300'))
        self.ollama_models = [m.strip() for m in os.getenv('OLLAMA_MODELS', 'qwen3:32b').split(',')]
        
        # MiniMax é…ç½®
        self.minimax_api_key = os.getenv('MINIMAX_API_KEY', '').strip()
        self.minimax_api_secret = os.getenv('MINIMAX_API_SECRET', '').strip()
        self.minimax_base_url = os.getenv('MINIMAX_BASE_URL', 'https://api.minimax.chat/v1').rstrip('/')
        self.minimax_model = os.getenv('MINIMAX_MODEL', 'abab6.5s-chat')
        
        # Gemini é…ç½®
        self.gemini_api_key = os.getenv('GEMINI_API_KEY', '').strip()
        self.gemini_base_url = os.getenv('GEMINI_BASE_URL', 'https://generativelanguage.googleapis.com/v1').rstrip('/')
        self.gemini_model = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash-lite')
        
        # é€‰æ‹© provider
        if provider == 'auto':
            if self._check_ollama():
                self.provider = 'ollama'
            elif self.minimax_api_key:
                self.provider = 'minimax'
            elif self.gemini_api_key:
                self.provider = 'gemini'
            else:
                raise ValueError("æœªé…ç½®ä»»ä½• LLM")
        elif provider == 'ollama':
            if not self._check_ollama():
                raise ValueError("Ollama ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…å¹¶è¿è¡Œ Ollama")
        elif provider == 'minimax':
            if not self.minimax_api_key:
                raise ValueError("MINIMAX_API_KEY æœªé…ç½®")
        elif provider == 'gemini':
            if not self.gemini_api_key:
                raise ValueError("GEMINI_API_KEY æœªé…ç½®")
    
    def _check_ollama(self) -> bool:
        """æ£€æŸ¥ Ollama æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.ollama_base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _switch_model(self, model_name: str) -> bool:
        """åˆ‡æ¢åˆ°æŒ‡å®šæ¨¡å‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            response = requests.get(f"{self.ollama_base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = [m['name'] for m in response.json().get('models', [])]
                if model_name not in models:
                    print(f"âš ï¸ æ¨¡å‹ {model_name} ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½...")
                    subprocess.run(['ollama', 'pull', model_name], check=True)
            
            # åŠ è½½æ¨¡å‹
            load_url = f"{self.ollama_base_url}/api/load"
            payload = {"model": model_name, "keep_alive": self.ollama_keep_alive}
            response = requests.post(load_url, json=payload, timeout=60)
            return response.status_code == 200
        except Exception as e:
            print(f"âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def generate_story_continuation(
        self,
        story_title: str,
        story_background: str,
        style_rules: str,
        previous_segments: list,
        language: str = 'zh',
        # æ–°å¢å‚æ•°
        story_summary: str = "",
        story_metadata: Dict = None,
        story_characters: list = None,
        story_outline: list = None,
    ) -> str:
        """
        ç”Ÿæˆæ•…äº‹ç»­å†™
        """
        context = {
            'title': story_title,
            'background': story_background,
            'style': style_rules,
            'previous_segments': '\n'.join([
                seg.get('content', '') for seg in previous_segments[-5:]
            ]),
            'segment_count': len(previous_segments),
            'summary': story_summary,
            'metadata': story_metadata or {},
            'characters': story_characters or [],
            'outline': story_outline or [],
        }
        
        prompt = self._build_prompt(context)
        
        # æŒ‰ provider è°ƒç”¨
        if self.provider == 'ollama':
            return self._call_ollama(prompt)
        elif self.provider == 'gemini':
            return self._call_gemini(prompt)
        elif self.provider == 'minimax':
            return self._call_minimax(prompt)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ provider: {self.provider}")
    
    def _build_prompt(self, context: dict) -> str:
        """æ„å»ºç»­å†™ prompt - åŒ…å«å®Œæ•´æ•…äº‹ä¿¡æ¯"""
        
        # æ„å»ºè§’è‰²ä¿¡æ¯
        characters_info = ""
        if context.get('characters'):
            chars = context['characters']
            if isinstance(chars, list):
                for char in chars[:5]:  # æœ€å¤š5ä¸ªè§’è‰²
                    if isinstance(char, dict):
                        characters_info += f"- {char.get('name', '')}: {char.get('description', '')}\n"
                    else:
                        characters_info += f"- {char}\n"
        
        # æ„å»ºå¤§çº²ä¿¡æ¯
        outline_info = ""
        if context.get('outline'):
            outline = context['outline']
            if isinstance(outline, list):
                for item in outline[:5]:  # æœ€å¤š5ä¸ªå¤§çº²èŠ‚ç‚¹
                    if isinstance(item, dict):
                        outline_info += f"- ç¬¬{item.get('chapter', '?')}ç« : {item.get('title', '')} - {item.get('summary', '')}\n"
                    else:
                        outline_info += f"- {item}\n"
        
        # æ„å»ºå…ƒæ•°æ®ä¿¡æ¯
        metadata_info = ""
        if context.get('metadata'):
            meta = context['metadata']
            if isinstance(meta, dict):
                genre = meta.get('genre', '')
                if genre:
                    metadata_info += f"ç±»å‹: {genre}\n"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•…äº‹ä½œå®¶ï¼Œä¸ºåä½œæ•…äº‹å¹³å°ç»­å†™å†…å®¹ã€‚è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ•…äº‹è®¾å®šã€‚

## æ•…äº‹åŸºæœ¬ä¿¡æ¯
æ ‡é¢˜ï¼š{context['title']}
èƒŒæ™¯ï¼š{context['background']}
ç±»å‹ï¼š{metadata_info}
å†™ä½œé£æ ¼ï¼š{context['style']}
å·²æœ‰ {context['segment_count']} ä¸ªç‰‡æ®µã€‚

## è§’è‰²è®¾å®š
{characters_info if characters_info else 'ï¼ˆæ— è§’è‰²è®¾å®šï¼‰'}

## æ•…äº‹å¤§çº²
{outline_info if outline_info else 'ï¼ˆæ— å¤§çº²ï¼‰'}

## å½“å‰æ•…äº‹è¿›å±•æ‘˜è¦
{context['summary'] if context['summary'] else 'ï¼ˆæš‚æ— æ‘˜è¦ï¼‰'}

## å‰æ–‡å†…å®¹ï¼ˆæœ€è¿‘5ä¸ªç‰‡æ®µï¼‰
{context['previous_segments'] if context['previous_segments'] else 'ï¼ˆæš‚æ— å‰æ–‡ï¼‰'}

## ç»­å†™è¦æ±‚
1. **å­—æ•°ï¼š300-500å­—**
2. **å¿…é¡»è¡”æ¥å‰æ–‡**ï¼Œå»¶ç»­æ•…äº‹ä¸»çº¿
3. **å¿…é¡»æ¨è¿›å‰§æƒ…**ï¼Œä¸èƒ½åŸåœ°è¸æ­¥
4. **ä¿æŒä¸€è‡´æ€§**ï¼šä¸–ç•Œè§‚ã€è§’è‰²æ€§æ ¼ã€å™äº‹é£æ ¼å¿…é¡»ä¸å‰æ–‡ä¸€è‡´
5. **æ³¨é‡ç»†èŠ‚**ï¼šå¿ƒç†æå†™ã€æ„Ÿå®˜æå†™ã€ç¯å¢ƒæå†™å¹¶é‡
6. **ç¦æ­¢**ï¼šä¸å‰æ–‡çŸ›ç›¾ã€è„±ç¦»ä¸»çº¿ã€æ— æ„ä¹‰çš„æµæ°´è´¦

## ç»­å†™æ ¼å¼
è¯·ç›´æ¥è¾“å‡ºç»­å†™å†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€è¯´æ˜ã€‚ç¡®ä¿å†…å®¹æœ‰å®è´¨æ€§æ¨è¿›ã€‚

"""
        
        return prompt
    
    def _call_gemini(self, prompt: str) -> str:
        """è°ƒç”¨ Google Gemini API"""
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY æœªé…ç½®")
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ Gemini Prompt (å‘é€ç»™ LLM)")
        print(f"{'='*60}")
        print(prompt[:3000])
        print(f"{'='*60}\n")
        
        url = f"{self.gemini_base_url}/models/{self.gemini_model}:generateContent"
        
        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "maxOutputTokens": 2000,
                "temperature": 0.7
            }
        }
        
        response = requests.post(
            f"{url}?key={self.gemini_api_key}",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=120
        )
        
        if response.status_code != 200:
            raise Exception(f"Gemini API é”™è¯¯: {response.status_code}")
        
        data = response.json()
        return data['candidates'][0]['content']['parts'][0]['text'].strip()
    
    def _call_ollama(self, prompt: str) -> str:
        """è°ƒç”¨ Ollama æœ¬åœ°æ¨¡å‹"""
        if not self._check_ollama():
            raise ValueError("Ollama ä¸å¯ç”¨")
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ Ollama Prompt (æ¨¡å‹: {self.ollama_model})")
        print(f"{'='*60}")
        print(prompt[:2000])
        print(f"{'='*60}\n")
        
        url = f"{self.ollama_base_url}/api/generate"
        
        payload = {
            "model": self.ollama_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "num_predict": 1000,
                "top_k": 40,
                "top_p": 0.9
            }
        }
        
        response = requests.post(url, json=payload, timeout=self.ollama_timeout)
        
        if response.status_code != 200:
            raise Exception(f"Ollama API é”™è¯¯: {response.status_code}")
        
        data = response.json()
        content = data.get('response', '').strip()
        
        # æ¸…ç†å¯èƒ½çš„ thinking å†…å®¹
        if '</think>' in content:
            content = content.split('</think>')[-1].strip()
        
        return content
    
    def _call_minimax(self, prompt: str) -> str:
        """è°ƒç”¨ MiniMax API"""
        if not self.minimax_api_key:
            raise ValueError("MINIMAX_API_KEY æœªé…ç½®")
        
        url = f"{self.minimax_base_url}/chat/completions"
        
        payload = {
            "model": self.minimax_model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_output_tokens": 1000
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.minimax_api_key}"
        }
        
        # æ·»åŠ  Group IDï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        group_id = getattr(self, 'minimax_group_id', None)
        if group_id and group_id != 'your_minimax_group_id_here':
            headers["X-GroupId"] = group_id
        
        response = requests.post(url, json=payload, headers=headers, timeout=120)
        
        if response.status_code != 200:
            raise Exception(f"MiniMax API é”™è¯¯: {response.status_code}")
        
        data = response.json()
        return data['choices'][0]['message']['content'].strip()


def create_llm_client(provider: str = 'auto') -> LLMClient:
    """åˆ›å»º LLM å®¢æˆ·ç«¯"""
    return LLMClient(provider)
