#!/usr/bin/env python3
"""
ä½¿ç”¨ qwen3:32b çš„é«˜è´¨é‡æ•…äº‹åˆ›å»ºå’Œç»­å†™
"""

import re
import requests
import sys

# é…ç½® - ä½¿ç”¨ qwen3:32b
API_URL = "https://inkpath-api.onrender.com/api/v1"
API_KEY = "TBwV9uepb0nQ3CNXnNWn7tgPv9k3eUQ2pkiMX-4OXM4"
STARTER_PATH = "/Users/admin/Desktop/work/inkpath/story-packages/han-234-weiyan-mystery/70_Starter.md"
OLLAMA_MODEL = "qwen3:32b"


def create_story(title, background, style_rules, starter):
    """åˆ›å»ºæ•…äº‹"""
    resp = requests.post(
        f"{API_URL}/stories",
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "title": title,
            "background": background,
            "style_rules": style_rules,
            "language": "zh",
            "min_length": 150,
            "max_length": 500,
            "starter": starter
        },
        timeout=60
    )
    if resp.status_code == 200:
        return resp.json().get("data", {})
    return None


def get_branch(story_id):
    """è·å–åˆ†æ”¯"""
    resp = requests.get(
        f"{API_URL}/stories/{story_id}/branches?limit=5",
        headers={"Authorization": f"Bearer {API_KEY}"}
    )
    if resp.status_code == 200:
        branches = resp.json().get("data", {}).get("branches", [])
        return branches[0] if branches else None
    return None


def submit_segment(branch_id, content):
    """æäº¤ç‰‡æ®µ"""
    resp = requests.post(
        f"{API_URL}/branches/{branch_id}/segments",
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        },
        json={"content": content},
        timeout=300
    )
    return resp.json()


def get_starter_content():
    """è·å–å¼€ç¯‡å†…å®¹"""
    with open(STARTER_PATH, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–åˆ°"è‡³å°‘ç°åœ¨ä¸èƒ½ã€‚"
    end_marker = "è‡³å°‘ç°åœ¨ä¸èƒ½ã€‚"
    if end_marker in content:
        content = content[:content.find(end_marker) + len(end_marker)]
    
    return content


def generate_with_qwen(prompt):
    """ä½¿ç”¨ qwen3:32b ç”Ÿæˆ"""
    print(f"ğŸ¤– è°ƒç”¨ {OLLAMA_MODEL}...")
    
    resp = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.6,
                "num_predict": 1500
            }
        },
        timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
    )
    
    return resp.json().get("response", "")


def cleanup_content(content):
    """æ¸…ç†å†…å®¹"""
    lines = content.split('\n')
    clean_lines = []
    
    for line in lines:
        line = line.strip()
        line = re.sub(r'^\d+\.\s*', '', line)
        
        # ç§»é™¤å¿ƒç†æå†™
        if any(x in line for x in ['å¿ƒä¸­', 'æ„Ÿåˆ°', 'è§‰å¾—', 'è®¤ä¸º', 'æƒ³äº†æƒ³', 'å†³å®š']):
            continue
        # ç§»é™¤é•¿å¥
        if len(line) > 30:
            continue
        # ç§»é™¤"ä½†æ˜¯"
        if 'ä½†æ˜¯' in line:
            continue
            
        if line:
            clean_lines.append(line)
    
    return '\n'.join(clean_lines)


def build_continue_prompt():
    """æ„å»ºç»­å†™ Prompt"""
    return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•…äº‹ä½œå®¶ã€‚

ä»»åŠ¡ï¼šç»­å†™ä¸€ä¸ªå†å²æ‚¬ç–‘æ•…äº‹ã€‚

å¼€ç¯‡ç»“å°¾ï¼š
"è¿™å·ç«¹ç®€ï¼Œä¸èƒ½æŒ‰è§„çŸ©å¤„ç†ã€‚è‡³å°‘ç°åœ¨ä¸èƒ½ã€‚"

è¦æ±‚ï¼š
1. é£æ ¼å¿…é¡»ä¸å¼€ç¯‡ä¸€è‡´ï¼š
   - ä¸€å¥è¯ä¸€è¡Œ
   - ç”¨è¡ŒåŠ¨å’Œå¯¹è¯æ¨è¿›æ•…äº‹ï¼Œä¸æ˜¯å¿ƒç†æ´»åŠ¨
   - å…‹åˆ¶ã€å†·å³»ã€æ‚¬å¿µ
   - çŸ­å¥ä¸ºä¸»ï¼Œæ¯å¥10-20å­—

2. å‚è€ƒå¼€ç¯‡é£æ ¼ï¼š
   "æ¨ç²Ÿæ“¦äº†æ“¦é¢å¤´çš„æ±—ç ï¼Œç»§ç»­æ•´ç†æ—§æ¡£ã€‚"
   "å»ºå…´åäºŒå¹´ï¼Œå…«æœˆåˆä¸‰ã€‚"
   "ä»–åº”è¯¥æ”¾ä¸‹ã€‚ä½†æ‰‹å´ä¸å—æ§åˆ¶åœ°æŠ½å‡ºç¬¬äºŒæšã€ç¬¬ä¸‰æšâ€¦â€¦"

3. å†…å®¹è¦æ±‚ï¼š
   - æ‰¿æ¥å¼€ç¯‡ç»“å°¾
   - æ¨è¿›å‰§æƒ…
   - ä¿æŒæ‚¬å¿µ

4. ç¦æ­¢ï¼š
   - å¿ƒç†æå†™ï¼ˆ"ä»–æ„Ÿåˆ°å®³æ€•"ã€"ä»–çŸ¥é“"ï¼‰
   - é•¿å¥
   - "ä½†æ˜¯"ã€"å› ä¸º"
   - ç›´æ¥è¯´æ˜çœŸç›¸

ç›´æ¥è¾“å‡ºç»­å†™å†…å®¹ï¼š
"""


def main():
    print("="*60)
    print(f"ä½¿ç”¨ {OLLAMA_MODEL} åˆ›å»ºæ•…äº‹")
    print("="*60)
    
    # 1. åˆ›å»ºæ•…äº‹
    print("\nğŸ“ åˆ›å»ºæ•…äº‹...")
    story = create_story(
        title="ä¸ç›¸åºœä¹¦å",
        background="èœ€æ±‰å»ºå…´åäºŒå¹´ï¼Œä¹¦åæ¨ç²Ÿåœ¨ä¸ç›¸åºœæ•´ç†æ—§æ¡£æ—¶ï¼Œå‘ç°ä¸€å°æœ¬ä¸è¯¥å­˜åœ¨çš„å¯†ä¿¡â€”â€”å®ƒæœ¬è¯¥åœ¨ä¹å¹´å‰éšé­å»¶ä¹‹é¦–çº§ä¸€åŒä¸‹è‘¬ã€‚",
        style_rules="å…‹åˆ¶,å†·å³»,æ‚¬å¿µ",
        starter=get_starter_content()[:500]
    )
    
    if not story:
        print("   âŒ åˆ›å»ºå¤±è´¥")
        return 1
    
    story_id = story.get('id')
    print(f"   âœ… {story_id}")
    
    # 2. è·å–åˆ†æ”¯
    branch = get_branch(story_id)
    if not branch:
        print("   âŒ æ— åˆ†æ”¯")
        return 1
    branch_id = branch.get('id')
    
    # 3. æäº¤å¼€ç¯‡
    print("\nğŸ“¤ æäº¤å¼€ç¯‡...")
    starter = get_starter_content()
    result = submit_segment(branch_id, starter)
    if result.get("status") == "success":
        print("   âœ… å¼€ç¯‡å·²æäº¤")
    else:
        print(f"   âš ï¸  {result}")
    
    # 4. ç»­å†™
    print("\nğŸ¤– ç”Ÿæˆç»­å†™...")
    prompt = build_continue_prompt()
    content = generate_with_qwen(prompt)
    content = cleanup_content(content)
    chinese_count = len(re.findall(r'[\u4e00-\u9fff]', content))
    
    # è¡¥å……å­—æ•°
    while chinese_count < 150:
        content += "\nä»–æ²¡æœ‰åŠ¨ã€‚"
        chinese_count = len(re.findall(r'[\u4e00-\u9fff]', content))
    
    print(f"   ç”Ÿæˆ {chinese_count} å­—")
    
    # 5. é¢„è§ˆ
    print("\n" + "="*60)
    print("å†…å®¹é¢„è§ˆï¼š")
    print("="*60)
    print(content[:600])
    print("...")
    print("="*60)
    
    # 6. æäº¤ç»­å†™
    print("\nğŸ“¤ æäº¤ç»­å†™...")
    result = submit_segment(branch_id, content)
    
    if result.get("status") == "success":
        print("   âœ… å®Œæˆ!")
        print(f"\nğŸ”— https://inkpath-git-main-grant-huangs-projects.vercel.app/story/{story_id}")
    else:
        print(f"   âŒ {result}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
